# exploration_mdps

# Outline:
 ● Select an MDP & a reward function
    ○ Gridworld
    ○ Extend Gridworld
■ Simplify to hexagonal grid (instead of 8 adjacent cells, there will be only 6)
■ Vary/extend the range of grid height values
■ 3D (i.e. Cubeworld, 26 adjacent cells)
■ Add more types of tiles in gridworld (i.e. hazards)
● Quicksand
● Water
● Implement RL Exploration Strategies:
○ Random
○ Greedy
○ Epsilon-Greedy
○ Boltzmann
● Measure RL strategies over the course of the roll-outs
○ Total reward (may not be possible if rewards are given at the end)
○ Difference between empirical values and optimal values
○ Number of steps to achieve goal
○ Convergence rate of trained expert (reward vs training epoch)
